# -*- coding: utf-8 -*-
"""tasks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aNHMyPCtBQp6XW4MGTG3pGM4PpAXqJUC
"""

import requests
from bs4 import BeautifulSoup

# Number of pages to scrape
num_pages = 20

# Base URL
base_url = "https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1"

# Parameters for the search query
params = {
    "k": "bags",
    "crid": "2M096C61O4MLT",
    "qid": "1653308124",
    "sprefix": "ba,aps,283",
    "ref": "sr_pg_"
}

# Scrape the data
for page in range(1, num_pages + 1):
    params['ref'] = f'sr_pg_{page}'
    response = requests.get(base_url, params=params)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Find all product containers
    product_containers = soup.find_all('div', {'data-component-type': 's-search-result'})
    
    # Extract information from each product container
    for container in product_containers:
        # Product URL
        product_url = container.find('a', {'class': 'a-link-normal s-no-outline'})['href']
        print("Product URL:", product_url)
        
        # Product Name
        product_name = container.find('span', {'class': 'a-size-medium a-color-base a-text-normal'}).text
        print("Product Name:", product_name)
        
        # Product Price
        product_price = container.find('span', {'class': 'a-offscreen'}).text
        print("Product Price:", product_price)
        
        # Rating
        rating = container.find('span', {'class': 'a-icon-alt'}).text
        print("Rating:", rating)
        
        # Number of reviews
        num_reviews = container.find('span', {'class': 'a-size-base'}).text
        print("Number of Reviews:", num_reviews)
        
        print("-------------------------------")

import requests
from bs4 import BeautifulSoup

# Number of pages to scrape
num_pages = 20

# Base URL
base_url = "https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1"

# Parameters for the search query
params = {
    "k": "bags",
    "crid": "2M096C61O4MLT",
    "qid": "1653308124",
    "sprefix": "ba,aps,283",
    "ref": "sr_pg_"
}

# Scrape the data
for page in range(1, num_pages + 1):
    params['ref'] = f'sr_pg_{page}'
    response = requests.get(base_url, params=params)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Find all product containers
    product_containers = soup.find_all('div', {'data-component-type': 's-search-result'})
    
    # Extract information from each product container
    for container in product_containers:
        # Product URL
        product_url = container.find('a', {'class': 'a-link-normal s-no-outline'})['href']
        print("Product URL:", product_url)
        
        # Product Name
        product_name = container.find('span', {'class': 'a-size-medium a-color-base a-text-normal'}).text
        print("Product Name:", product_name)
        
        # Product Price
        product_price = container.find('span', {'class': 'a-offscreen'}).text
        print("Product Price:", product_price)
        
        # Rating
        rating = container.find('span', {'class': 'a-icon-alt'}).text
        print("Rating:", rating)
        
        # Number of reviews
        num_reviews = container.find('span', {'class': 'a-size-base'}).text
        print("Number of Reviews:", num_reviews)
        
        print("                              ")